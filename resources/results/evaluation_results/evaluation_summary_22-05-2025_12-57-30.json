{
  "total_output_questions": 72,
  "total_evaluated_questions": 72,
  "outcome_classification": {
    "accuracy": 0.8194444444444444,
    "category_metrics": {
      "Yes": {
        "precision": 0.5,
        "recall": 0.8571428571428571,
        "f1-score": 0.631578947368421,
        "support": 7.0
      },
      "No - Unrelated event": {
        "precision": 0.8983050847457628,
        "recall": 0.9464285714285714,
        "f1-score": 0.9217391304347826,
        "support": 56.0
      },
      "No - condition(s) not met": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 9.0
      }
    }
  },
  "exact_outcome_matches": 59,
  "exact_outcome_match_percentage": 81.94444444444444,
  "avg_justification_similarity": 0.8523969997491194,
  "avg_justification_iou": 0.8559704483326265,
  "avg_payment_similarity": 0.8225871051289487,
  "avg_combined_justification_similarity": 0.8374920524390341
}