{
  "total_output_questions": 40,
  "total_evaluated_questions": 40,
  "outcome_classification": {
    "accuracy": 0.675,
    "category_metrics": {
      "Yes": {
        "precision": 0.2857142857142857,
        "recall": 0.4,
        "f1-score": 0.3333333333333333,
        "support": 5.0
      },
      "No - Unrelated event": {
        "precision": 0.8888888888888888,
        "recall": 0.8275862068965517,
        "f1-score": 0.8571428571428571,
        "support": 29.0
      },
      "No - condition(s) not met": {
        "precision": 0.16666666666666666,
        "recall": 0.2,
        "f1-score": 0.18181818181818182,
        "support": 5.0
      },
      "Maybe": {
        "precision": 0.0,
        "recall": 0.0,
        "f1-score": 0.0,
        "support": 1.0
      }
    }
  },
  "exact_outcome_matches": 27,
  "exact_outcome_match_percentage": 67.5,
  "avg_justification_similarity": 0.10283365676452108,
  "avg_justification_iou": 0.10745399433786859,
  "avg_payment_similarity": 0.7594210206344097,
  "avg_combined_justification_similarity": 0.4311273386994654
}