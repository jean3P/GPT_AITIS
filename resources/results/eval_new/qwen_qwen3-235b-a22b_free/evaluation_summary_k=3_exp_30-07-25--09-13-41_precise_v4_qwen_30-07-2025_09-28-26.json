{
  "model_name": "qwen_qwen3-235b-a22b_free",
  "k_configuration": "k=3",
  "experiment_timestamp": "30-07-25--09-13-41",
  "prompt_name": "precise_v4_qwen",
  "total_output_questions": 108,
  "total_evaluated_questions": 108,
  "outcome_classification": {
    "accuracy": 0.5648148148148148,
    "category_metrics": {
      "Yes": {
        "precision": 0.42424242424242425,
        "recall": 0.5833333333333334,
        "f1-score": 0.49122807017543857,
        "support": 24.0
      },
      "No - Unrelated event": {
        "precision": 0.7096774193548387,
        "recall": 0.6470588235294118,
        "f1-score": 0.676923076923077,
        "support": 68.0
      },
      "No - condition(s) not met": {
        "precision": 0.23076923076923078,
        "recall": 0.1875,
        "f1-score": 0.20689655172413793,
        "support": 16.0
      }
    }
  },
  "exact_outcome_matches": 61,
  "exact_outcome_match_percentage": 56.481481481481474,
  "avg_justification_similarity": 0.5013270630538423,
  "avg_justification_iou": 0.4758663964652367,
  "avg_payment_similarity": 0.6967813975904875,
  "avg_combined_justification_similarity": 0.599054230322165
}